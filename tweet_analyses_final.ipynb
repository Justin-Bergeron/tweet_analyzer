{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################credentials\n",
    "\n",
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "#Twitter API credentials\n",
    "consumer_key = \"GvauzqzfE2o1eqIHxk5X8q38u\"\n",
    "consumer_secret = \"cBfUvQ37EbQKPP2FjyhqVxTyCrBqnlEa8bts81C5SWOUDxpXsA\"\n",
    "access_token = \"980991539739484160-jivEu1NrRKe7rLsHr3ZBBf2YRtYSWab\"\n",
    "access_token_secret = \"GPcMoprjKx5D7lhvA3Xj10diRnhcHBLsowELyfE1EuoHN\"\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #authorize twitter, initialize tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#########################get the twitter handle to put into the formula\n",
    "def WhoThere():\n",
    "\n",
    "    # Twitter Credentials\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n",
    "    # Search for all tweets\n",
    "    public_tweets = api.search('@bobbobe37676119', count=1, result_type=\"recent\")\n",
    "\n",
    "    # Loop through all tweets\n",
    "    for tweet in public_tweets[\"statuses\"]:\n",
    "       \n",
    "        global tweet_id\n",
    "        global tweet_author\n",
    "        global target_term\n",
    "        # Get ID and Author of most recent tweet directed to me\n",
    "        tweet_id = tweet[\"id\"]\n",
    "        tweet_author = tweet[\"user\"][\"screen_name\"]\n",
    "        tweet_text = tweet[\"text\"]\n",
    "        target_term = str('@' + tweet['entities'][\"user_mentions\"][1]['screen_name'])\n",
    "        \n",
    "        \n",
    "        # Print the tweet_text\n",
    "        print(tweet_text)\n",
    "        print(target_term)\n",
    "WhoThere\n",
    "\n",
    "\n",
    "#####################################get all the tweets from the target\n",
    "\n",
    "def gettweets():\n",
    "\n",
    "    #target_term = \"washingtonpost\" \n",
    "\n",
    "\n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    global alltweets\n",
    "    alltweets = []\n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.search(target_term, count=100)   #, result_type=\"recent\"\n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(alltweets) < 500:\n",
    "        #print \"getting tweets before %s\" % (oldest)\n",
    "        \n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.search(target_term, count=100,max_id=oldest)\n",
    "        \n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        \n",
    "        #print \"...%s tweets downloaded so far\" % (len(alltweets))\n",
    "    print(len(alltweets))\n",
    "\n",
    " \n",
    "\n",
    "############################analyze the tweets\n",
    "def analyze():\n",
    "\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    #test = alltweets[0]\n",
    "    json_str = json.dumps(alltweets[2]._json)     #parse json now that we have the tweets\n",
    "    #print(json_str)\n",
    "\n",
    "    #print((alltweets)[1])\n",
    "    #print(type(alltweets[1]))\n",
    "    global forx\n",
    "    global sentiment\n",
    "    sentiment = []\n",
    "    forx = []\n",
    "    tweet_id = []\n",
    "    jdic = []\n",
    "    w=1\n",
    "\n",
    "    jsontweets = []\n",
    "\n",
    "    for tweet in alltweets:\n",
    "        #convert to json\n",
    "        y = json.dumps(tweet._json)\n",
    "        #y = json.loads(tweet._json)\n",
    "        jsontweets.append(y)\n",
    "\n",
    "    for item in jsontweets:\n",
    "        d = json.loads(item)\n",
    "        jdic.append(d)\n",
    "    #print(jdic[0]['text'])\n",
    "    \n",
    "    #print(len(jsontweets))\n",
    "    #print(type(jsontweets[0]))\n",
    "\n",
    "    #d = json.loads(jsontweets[0])\n",
    "    #print(d['text'])\n",
    "    super = []\n",
    "\n",
    "    print(type(jdic[8]))\n",
    "\n",
    "  \n",
    "    compound = analyzer.polarity_scores(jdic[8][\"text\"])[\"compound\"]\n",
    "    print(compound)\n",
    "    i = 0\n",
    "    texttext=[]\n",
    "    while i < 500:\n",
    "    \n",
    "        # Run Vader Analysis on each tweet\n",
    "        compound = analyzer.polarity_scores(jdic[i][\"text\"])[\"compound\"]\n",
    "        texty = jdic[i][\"text\"]\n",
    "        #pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "        #neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "        #neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "\n",
    "        # Add each value to the appropriate array\n",
    "        sentiment.append(compound)\n",
    "        texttext.append(texty)\n",
    "        #sentiment.append(neu)\n",
    "        #sentiment.append(neg)\n",
    "        i += 1\n",
    "        w -= 1\n",
    "        forx.append(w)\n",
    "    #print(sentiment)\n",
    "    #print(texttext)\n",
    "\n",
    "\n",
    "########################make a dope plot\n",
    "def plot():\n",
    "    \n",
    "    now = datetime.datetime.now() \n",
    "    today = now.strftime(\"%Y-%m-%d\")    \n",
    "    # Create data\n",
    "    #N = 500\n",
    "    x = forx\n",
    "    y = sentiment\n",
    "    colors = (0,0,0)\n",
    "    area = np.pi*3\n",
    " \n",
    "    # Plot\n",
    "    plt.scatter(x, y, s=area, c=colors, alpha=0.5)\n",
    "    plt.title(f'Sentiment Analysis of {target_term}\\'s Tweets {today}')\n",
    "    plt.xlabel('Tweets Ago')\n",
    "    plt.ylabel('Tweet Polarity')\n",
    "    plt.savefig('/Users/justin/Documents/2018/ucsd/tweetanalhw/botplot2.png')\n",
    "    plt.show()\n",
    "\n",
    "############################# tweet out the graph and shit\n",
    "def ThankYou():\n",
    "\n",
    "    # Twitter Credentials\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n",
    "    # Search for all tweets\n",
    "    public_tweets = api.search('@bobbobe37676119', count=1, result_type=\"recent\")\n",
    "\n",
    "    # Loop through all tweets\n",
    "    for tweet in public_tweets[\"statuses\"]:\n",
    "       \n",
    "        global tweet_id\n",
    "        global tweet_author\n",
    "        global target_term\n",
    "        # Get ID and Author of most recent tweet directed to me\n",
    "        tweet_id = tweet[\"id\"]\n",
    "        tweet_author = tweet[\"user\"][\"screen_name\"]\n",
    "        tweet_text = tweet[\"text\"]\n",
    "        target_term = str('@' + tweet['entities'][\"user_mentions\"][1]['screen_name'])\n",
    "        \n",
    "        \n",
    "        # Print the tweet_text\n",
    "        print(tweet_text)\n",
    "        print(target_term)\n",
    "\n",
    "        # Use Try-Except to avoid the duplicate error\n",
    "        try:\n",
    "            # Respond to tweet\n",
    "            api.update_with_media(\"/Users/justin/Documents/2018/ucsd/tweetanalhw/botplot2.png\",\n",
    "                      f\"Hey @{tweet_author}! Here is that graph you wanted for {target_term}!\", in_reply_to_status_id=tweet_id)\n",
    "\n",
    "            # Print success message\n",
    "            print(\"Successful response!\")\n",
    "\n",
    "        except Exception:            # Print message if duplicate\n",
    "            print(\"Already responded to this one!\")\n",
    "\n",
    "        # Print message to signify complete cycle\n",
    "        print(\"We're done for now. I'll check again in 5 minutes.\")\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@bobbobe37676119  @just15908306\n",
      "@just15908306\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "[{'message': 'Rate limit exceeded', 'code': 88}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-af9c8fd86767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mWhoThere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mgettweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-badaa9b42597>\u001b[0m in \u001b[0;36mgettweets\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m#all subsiquent requests use the max_id param to prevent duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mnew_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moldest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m#save most recent tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;31m# Set pagination mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_rate_limit_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRateLimitError\u001b[0m: [{'message': 'Rate limit exceeded', 'code': 88}]"
     ]
    }
   ],
   "source": [
    "\n",
    "while(True):\n",
    "    WhoThere()    \n",
    "    gettweets()\n",
    "    analyze()\n",
    "    plot()  \n",
    "    ThankYou()\n",
    "    time.sleep(300)  \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
